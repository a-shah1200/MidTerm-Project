{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cthpz7dpXEIP",
        "outputId": "bfea4fec-479e-42bf-c72c-e08aa2592d33"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate incomplete classfier dataset from bookcorpus dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Lw37IxmBW2Gi"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import random\n",
        "random.seed(1)  # For consistency between the runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UlXmxOxZYP5E"
      },
      "outputs": [],
      "source": [
        "class GenerateDataset():\n",
        "  def __init__(self, dataset,length,is_train=True,min_length=8, max_length=20):\n",
        "    self.dataset = load_dataset(dataset) # Can take a lot of time depending upon dataset\n",
        "    if is_train:\n",
        "      self.dataset=self.dataset[\"train\"]\n",
        "    # mixed dataset\n",
        "    self.dataset = self.dataset.shuffle(seed=55)\n",
        "    self.length=length\n",
        "    self.min_length=min_length\n",
        "    self.max_length=max_length\n",
        "    # self.dataset=self.get_dataset()\n",
        "    # self.__dataset=self.preprocess(self.dataset)  # For debugging purposes only\n",
        "    self.__dataset=self.preprocess_test(self.dataset) # directly preprocess the dataset \n",
        "    self.dataset=self.gen_incomplete(self.__dataset)\n",
        "\n",
        "  @property\n",
        "  def complete_dataset(self):\n",
        "    return self.__dataset\n",
        "\n",
        "  def get_dataset(self,param=None):\n",
        "    if param==None:\n",
        "      premlim_li=random.choices(self.dataset,k=self.length)\n",
        "    else:\n",
        "      premlim_li=random.choices(self.dataset,k=param)\n",
        "    return premlim_li\n",
        "  \n",
        "  def preprocess_test(self,li):\n",
        "    buffer = []\n",
        "    n = self.length\n",
        "    for i in li:\n",
        "      if len(i[\"text\"].strip().split()) > self.min_length and i[\"text\"] not in buffer and \"**\" not in i[\"text\"]:\n",
        "        buffer.append(i[\"text\"])\n",
        "        n -= 1\n",
        "      if n == 0:\n",
        "        break\n",
        "    return buffer\n",
        "  \n",
        "  # def redundant_character(self,sentence,check=[\" \",\"'\",\"''\"]):\n",
        "  #   arr=sentence[\"text\"].strip().split()\n",
        "  #   count=len(arr)\n",
        "  #   for i in arr:\n",
        "  #     if i in check:\n",
        "  #       count-=1\n",
        "  #   return count\n",
        "\n",
        "  # def preprocess(self,li):\n",
        "  #   buffer=[]\n",
        "  #   count=0\n",
        "  #   max_iter=1000\n",
        "  #   while True:\n",
        "  #     max_iter-=1\n",
        "  #     if max_iter==0:\n",
        "  #       if len(buffer)<self.length:\n",
        "  #         temp=self.get_dataset(self.length-len(buffer))\n",
        "  #         buffer.extend([i[\"text\"] for i in temp])\n",
        "  #       break\n",
        "  #     for i in li:\n",
        "  #       if self.redundant_character(i)<=self.min_length:\n",
        "  #         count+=1\n",
        "  #       else:\n",
        "  #         buffer.append(i[\"text\"])\n",
        "  #     if count==0 or len(buffer)==self.length:\n",
        "  #       break\n",
        "  #     else:\n",
        "  #       li=self.get_dataset(count)\n",
        "  #       count=0\n",
        "  #   return buffer\n",
        "\n",
        "  def gen_incomplete(self,pre_li):\n",
        "    buffer=[]\n",
        "    for i in pre_li:\n",
        "      arr=i.strip().split()\n",
        "      if len(arr) > self.max_length:\n",
        "        buffer.append(\" \".join(arr[:8]))\n",
        "      else:\n",
        "        buffer.append(\" \".join(arr[:(len(arr)//2)]))\n",
        "\n",
        "    return buffer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.dataset[idx]\n",
        "\n",
        "  def toCSV(self):\n",
        "    df=pd.DataFrame([i for i in self.dataset],columns=[\"x_i\"])\n",
        "    df.to_csv(\"incomplete_dataset.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "85fce7e1654447cf940f2c1b2d81d7de",
            "7803efdddba043c7a535ef3d17a5d2e4",
            "1484f1945ba14acaa3d95fdfa52f559e",
            "e29bb8f709c34f72824c9673cd38a76b",
            "113bea675fa341bb85a80120f1dfb8dd",
            "d4862734702f43b987367c4c9de88d06",
            "4ac82a9079184fe8a5ba48bda8988a47",
            "803fc279b6184eb7a5ba0019fd47bb83",
            "3d417d3e76ff4397b25cd6790ef2b467",
            "e262ac1ab20740f889f9814b88a27e96",
            "c8157bd160b94dc09d8944dcb2a337f4"
          ]
        },
        "id": "PXSple02n6qH",
        "outputId": "ca7d4e22-8602-4170-8453-2ba537369eed"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'GenerateDataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mGenerateDataset\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbookcorpus\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mtoCSV()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'GenerateDataset' is not defined"
          ]
        }
      ],
      "source": [
        "data=GenerateDataset(\"bookcorpus\",10)\n",
        "data.toCSV()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2QFIoUhSrXFx",
        "outputId": "d0b955f0-e3dc-4941-b495-13c45b8f2c7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'um , yeah , i got a flat'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[95]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "W_pCyjaShTK6",
        "outputId": "521cefb4-2a3d-4a41-df96-dea53a119081"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\YEH\\AppData\\Local\\Temp\\ipykernel_12484\\884775774.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df_cleaned = df.applymap(lambda x: x.replace(\"`\", \"\") if isinstance(x, str) else x)\n",
            "C:\\Users\\YEH\\AppData\\Local\\Temp\\ipykernel_12484\\884775774.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df_cleaned = df_cleaned.applymap(lambda x: x.replace('\"\"', \"\") if isinstance(x, str) else x)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>x_i</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>terry said , let me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>i have forever dreamed of belonging to callias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>kyle started yipping then changed to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>and i happen to know this side of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>i think he feels ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                             x_i\n",
              "0           0                             terry said , let me\n",
              "1           1  i have forever dreamed of belonging to callias\n",
              "2           2            kyle started yipping then changed to\n",
              "3           3               and i happen to know this side of\n",
              "4           4                            i think he feels ..."
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('incomplete_dataset.csv')\n",
        "\n",
        "# Replace all instances of \"`\" with an empty string in the entire DataFrame or a specific column\n",
        "df_cleaned = df.applymap(lambda x: x.replace(\"`\", \"\") if isinstance(x, str) else x)\n",
        "\n",
        "# replace all instances of \"\"\" with an empty string in the entire DataFrame or a specific column\n",
        "df_cleaned = df_cleaned.applymap(lambda x: x.replace('\"\"', \"\") if isinstance(x, str) else x)\n",
        "\n",
        "# If you want to do this for a specific column, let's say 'text_column'\n",
        "# df['text_column'] = df['text_column'].str.replace(\"``\", \"\")\n",
        "\n",
        "# Save the cleaned dataset\n",
        "df_cleaned.to_csv('cleaned_dataset.csv', index=False)\n",
        "\n",
        "# Display the cleaned data\n",
        "df_cleaned.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install SentencePiece\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check GPU availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "12.1\n",
            "GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU\n",
            "Device Count: 1\n",
            "Allocated memory: 0.00 MB\n",
            "Reserved memory: 5458.00 MB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "print(torch.cuda.is_available())  # This should return True if a GPU is available\n",
        "print(torch.version.cuda)\n",
        "\n",
        "# If True, print details about the GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Device Count: {torch.cuda.device_count()}\")\n",
        "\n",
        "# Check memory usage on GPU\n",
        "allocated_memory = torch.cuda.memory_allocated() / 1024 ** 2  # Convert to MB\n",
        "reserved_memory = torch.cuda.memory_reserved() / 1024 ** 2    # Convert to MB\n",
        "\n",
        "print(f\"Allocated memory: {allocated_memory:.2f} MB\")\n",
        "print(f\"Reserved memory: {reserved_memory:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sentences generation and classfier dataset completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\YEH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "  3%|▎         | 168/5000 [00:57<29:44,  2.71it/s]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPTNeoForCausalLM\n",
        "from transformers import XLNetTokenizer, XLNetLMHeadModel\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
        "from transformers import CTRLTokenizer, CTRLLMHeadModel\n",
        "from transformers import ReformerTokenizer, ReformerModelWithLMHead\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load dataset\n",
        "test_dataset_path = 'test_dataset.csv'\n",
        "cleaned_dataset_path = 'cleaned_dataset.csv'\n",
        "cleaned_df = pd.read_csv(cleaned_dataset_path)\n",
        "test_df = pd.read_csv(test_dataset_path)\n",
        "\n",
        "# Set the device to GPU or CPU    \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def get_model_token(model_name, device):\n",
        "    match model_name:\n",
        "        case \"GPT2\":\n",
        "            model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
        "            tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "            saved_path = \"completed_dataset_GPT2.csv\"\n",
        "        case \"XLNet\":\n",
        "            model = XLNetLMHeadModel.from_pretrained(\"xlnet-base-cased\").to(device)\n",
        "            tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "            saved_path = \"completed_dataset_XLNet.csv\"\n",
        "        case \"BART\":\n",
        "            model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\").to(device)\n",
        "            tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "            saved_path = \"completed_dataset_BART.csv\"\n",
        "        case \"T5\":\n",
        "            model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n",
        "            tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "            saved_path = \"completed_dataset_T5.csv\"\n",
        "        case \"Pegasus\":\n",
        "            model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\").to(device)\n",
        "            tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
        "            saved_path = \"completed_dataset_Pegasus.csv\"\n",
        "        case \"CTRL\":\n",
        "            model = CTRLLMHeadModel.from_pretrained(\"ctrl\").to(device)\n",
        "            tokenizer = CTRLTokenizer.from_pretrained(\"ctrl\")\n",
        "            saved_path = \"completed_dataset_CTRL.csv\"\n",
        "        case \"Reformer\":\n",
        "            model = ReformerModelWithLMHead.from_pretrained(\"google/reformer-crime-and-punishment\").to(device)\n",
        "            tokenizer = ReformerTokenizer.from_pretrained(\"google/reformer-crime-and-punishment\")\n",
        "            saved_path = \"completed_dataset_Reformer.csv\"\n",
        "        case \"GPT_NEO\":\n",
        "            model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-125M\").to(device)\n",
        "            tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
        "            saved_path = \"completed_dataset_GPT_NEO.csv\"\n",
        "        case \"Alpaca\":\n",
        "            model = AutoModelForCausalLM.from_pretrained(\"chavinlo/alpaca-native\").to(device)\n",
        "            tokenizer = AutoTokenizer.from_pretrained(\"chavinlo/alpaca-native\")\n",
        "            saved_path = \"completed_dataset_Alpaca.csv\"\n",
        "        case \"GPT4ALL\":\n",
        "            model = AutoModelForCausalLM.from_pretrained(\"nomic-ai/gpt4all-j\").to(device)\n",
        "            tokenizer = AutoTokenizer.from_pretrained(\"nomic-ai/gpt4all-j\")\n",
        "            saved_path = \"completed_dataset_GPT4ALL.csv\"\n",
        "        case _:\n",
        "            raise ValueError(\"Invalid model name. Please choose from: GPT2, XLNet, BART, T5, Pegasus, CTRL, Reformer, GPT_NEO, Alpaca, GPT4ALL\")\n",
        "            return None, None, None\n",
        "    return model, tokenizer, saved_path\n",
        "# Arguments: model_name, running device, dataset\n",
        "def Complete_by_model(model_name, device, dataset):\n",
        "    # Load pre-trained model and tokenizer\n",
        "    model, tokenizer, saved_path = get_model_token(model_name, device)\n",
        "    if model is None:\n",
        "        return\n",
        "    \n",
        "    # Function to generate sentence completions without duplicating x_i and stopping at the first period\n",
        "    def complete_sentence(input_text):\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "        outputs = model.generate(inputs[\"input_ids\"], max_length=50, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
        "        completed_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # # Monitor the progress with percentage\n",
        "        # print(f\"Input: {input_text}\")\n",
        "        # print(f\"Output: {completed_sentence}\\n\")\n",
        "\n",
        "        # Remove the original input_text part from the generated completion\n",
        "        completion_only = completed_sentence[len(input_text):].strip()\n",
        "        \n",
        "        # Remove all \\n characters\n",
        "        completion_only = completion_only.replace('\\n', ' ')\n",
        "        \n",
        "        # Find the first period, and if not found, find the first comma\n",
        "        first_period_index = completion_only.find('.')\n",
        "        if first_period_index != -1 and first_period_index != 0:\n",
        "            completion_only = completion_only[:first_period_index + 1]  # Include the period\n",
        "        else:\n",
        "            # Find the position of the second comma\n",
        "            commas = [pos for pos, char in enumerate(completion_only) if char == ',']\n",
        "            if len(commas) >= 2:\n",
        "                completion_only = completion_only[:commas[1] + 1]  # Sentence more than two commas, then get the first two\n",
        "            elif len(commas) == 1:\n",
        "                    completion_only = completion_only[:commas[0] + 1]  # Sentence with only one comma, then get the first one\n",
        "        return completion_only\n",
        "    # Apply the completion process to each sentence in the x_i column\n",
        "    tqdm.pandas()  # Add progress bar\n",
        "    dataset['x_j'] = dataset['x_i'].progress_apply(complete_sentence)\n",
        "\n",
        "    # Save the completed dataset\n",
        "    dataset.to_csv(saved_path, index=False)\n",
        "\n",
        "\n",
        "#### Complete the dataset using different models\n",
        "# Clear GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Complete_by_model(\"GPT2\", device, cleaned_df) # Accepable completions\n",
        "# Complete_by_model(\"XLNet\", device, cleaned_df)    # Nonsensical completions\n",
        "# Complete_by_model(\"BART\", device, cleaned_df)    # Nonsensical completions\n",
        "# Complete_by_model(\"T5\", device, cleaned_df)       # Nonsensical completions\n",
        "# Complete_by_model(\"Pegasus\", device, cleaned_df)  # Backup option\n",
        "# Complete_by_model(\"CTRL\", device, cleaned_df)   # Nonsensical completions\n",
        "Complete_by_model(\"Reformer\", device, cleaned_df) # Accepable completions\n",
        "# Complete_by_model(\"GPT_NEO\", device, cleaned_df)  # Acceptable completions\n",
        "# Complete_by_model(\"Alpaca\", device, cleaned_df)   # CUDA out of memory (24GB needed)\n",
        "#Complete_by_model(\"GPT4ALL\", device, cleaned_df)   # CUDA out of memory (24GB needed)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "113bea675fa341bb85a80120f1dfb8dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1484f1945ba14acaa3d95fdfa52f559e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803fc279b6184eb7a5ba0019fd47bb83",
            "max": 74004228,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d417d3e76ff4397b25cd6790ef2b467",
            "value": 74004228
          }
        },
        "3d417d3e76ff4397b25cd6790ef2b467": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ac82a9079184fe8a5ba48bda8988a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7803efdddba043c7a535ef3d17a5d2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4862734702f43b987367c4c9de88d06",
            "placeholder": "​",
            "style": "IPY_MODEL_4ac82a9079184fe8a5ba48bda8988a47",
            "value": "Generating train split: 100%"
          }
        },
        "803fc279b6184eb7a5ba0019fd47bb83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85fce7e1654447cf940f2c1b2d81d7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7803efdddba043c7a535ef3d17a5d2e4",
              "IPY_MODEL_1484f1945ba14acaa3d95fdfa52f559e",
              "IPY_MODEL_e29bb8f709c34f72824c9673cd38a76b"
            ],
            "layout": "IPY_MODEL_113bea675fa341bb85a80120f1dfb8dd"
          }
        },
        "c8157bd160b94dc09d8944dcb2a337f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4862734702f43b987367c4c9de88d06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e262ac1ab20740f889f9814b88a27e96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e29bb8f709c34f72824c9673cd38a76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e262ac1ab20740f889f9814b88a27e96",
            "placeholder": "​",
            "style": "IPY_MODEL_c8157bd160b94dc09d8944dcb2a337f4",
            "value": " 74004228/74004228 [28:21&lt;00:00, 32736.17 examples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
